{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68cd071d",
   "metadata": {},
   "source": [
    "# Mineração de Regras de Associação do Dataset SAGE\n",
    "_Refinamento e busca de padrões para desenvolvimento de experiências gamificadas_\n",
    "\n",
    "Para o primeiro trabalho da disciplina de Inteligência Computacional, devemos selecionar um dataset público para mineração de dados resultando na coleta de regras de associação.\n",
    "\n",
    "O dataset utilizado foi publicado através de uma pesquisa com o intuito de ampliar a base de dados ligadas a jogos gamificados com o propósito de analisar as preferências de usuários e como enchergam diversas características ligadas ao game design.\n",
    "\n",
    "## Link para publicação\n",
    "[SAGE: A dataset for Smart Adaptive Gamified Education](https://sol.sbc.org.br/index.php/sbie/article/view/26738/26557)\n",
    "\n",
    "O [dataset original](https://github.com/ArmandoToda/Paper_SBIE2023) pode ser encontrado no repositório do autor no github."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b9903",
   "metadata": {},
   "source": [
    "# Metodologia\n",
    "Criei o repositório e arquivo jupyter para executar as etapas de mineração necessárias para busca de regras de associação:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c540b0ad",
   "metadata": {},
   "source": [
    "## Definição de variáveis para operação do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b7dcfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "##Variáveis iniciais de referência\n",
    "csv_filename = \"SAGEDataset.csv\"\n",
    "# URL do arquivo XLSX no GitHub\n",
    "xlsx_url = \"https://github.com/ArmandoToda/Paper_SBIE2023/raw/main/DATA.xlsx\"\n",
    "# Nome temporário para o arquivo XLSX baixado\n",
    "xlsx_filename = \"DATA.xlsx\"\n",
    "\n",
    "##Filtro de dados podem ser usados para montar nichos diferentes no dataset\n",
    "# Exemplo de filtro para o gênero de jogo, país de origem, gênero do jogador, idade, etc.\n",
    "filterBy = {\n",
    "    # 'country': ['br', 'us', 'gr', 'uk', 'cn', 'it', 'in', 'es', 'de', 'fr'],\n",
    "    # 'game_genre': ['action'],\n",
    "}\n",
    "\n",
    "min_products = 3\n",
    "min_support = 0.3\n",
    "confidence = 0.85\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac44296d",
   "metadata": {},
   "source": [
    "## Obtenção do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8ae5786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGEDataset.csv já existe. Nenhuma ação necessária.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"assets/\"+csv_filename):\n",
    "    print(f\"{csv_filename} não encontrado. Baixando e convertendo...\")\n",
    "    \n",
    "    # Baixa o arquivo XLSX\n",
    "    response = requests.get(xlsx_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(xlsx_filename, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Arquivo baixado: {xlsx_filename}\")\n",
    "    else:\n",
    "        raise Exception(f\"Falha ao baixar o arquivo. Status code: {response.status_code}\")\n",
    "    \n",
    "    \"\"\"Converte um arquivo XLSX para CSV.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_excel(xlsx_filename)\n",
    "        data.to_csv(\"assets/\"+csv_filename, index=False)\n",
    "        print(f\"Arquivo convertido para CSV: {csv_filename}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erro ao converter XLSX para CSV: {e}\")\n",
    "    \n",
    "    # Remove o arquivo XLSX temporário\n",
    "    if os.path.exists(xlsx_filename):\n",
    "        os.remove(xlsx_filename)\n",
    "        print(f\"Arquivo temporário removido: {xlsx_filename}\")\n",
    "else:\n",
    "    print(f\"{csv_filename} já existe. Nenhuma ação necessária.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e77143",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12ce5139",
   "metadata": {},
   "source": [
    "## Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12dcaa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras linhas do dataset:\n",
      "   gender age_group country years_playing time_per_week game_genre  \\\n",
      "0    male     25-34      uk         21-30         26-30     action   \n",
      "1    male       <15      us           <10         26-30     action   \n",
      "2  female     15-24      us           <10            <5     action   \n",
      "3    male     15-24      br         10-20          5-15     action   \n",
      "4    male     15-24      br         10-20            <5     action   \n",
      "\n",
      "   setting_multiplayer  points  levels  cooperation  ...  acknowledgment  \\\n",
      "0                False       4       5            3  ...               5   \n",
      "1                False       2       2            3  ...               1   \n",
      "2                 True       5       4            4  ...               4   \n",
      "3                False       5       4            2  ...               3   \n",
      "4                False       2       3            4  ...               5   \n",
      "\n",
      "   stats  rarity  imposed_choice  time_pressure  economy  sensation  \\\n",
      "0      4       4               3              2        4          4   \n",
      "1      5       4               2              2        2          5   \n",
      "2      3       3               4              2        4          3   \n",
      "3      5       2               3              1        5          5   \n",
      "4      3       2               3              3        2          4   \n",
      "\n",
      "   reputation  narrative  storytelling  \n",
      "0           4          5             5  \n",
      "1           1          4             4  \n",
      "2           3          5             4  \n",
      "3           1          5             5  \n",
      "4           3          2             2  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "Dataset limpo salvo em: assets/Cleaned_SAGEDataset.csv\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"assets/\"+csv_filename)  # Use csv_filename em vez de file_path\n",
    "    \n",
    "    # Remover duplicatas\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Remover linhas inválidas (com valores NaN)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    df['gender'] = df['gender'].apply(lambda x: \"male\" if x == \"Male\" else \"female\" if x == \"Female\" else \"other\")\n",
    "    df['age_group'] = pd.cut(df['age_in_years'], bins=[0, 14, 24, 34, 44, float('inf')], \n",
    "                            labels=['<15', '15-24', '25-34', '35-44', '>44'])\n",
    "    df.drop('age_in_years', axis=1, inplace=True)\n",
    "    df['years_playing'] = pd.cut(df['years_playing'], bins=[0, 10, 20, 30, float('inf')], \n",
    "                                labels=['<10', '10-20', '21-30', '>30'])\n",
    "    \n",
    "    # print(df['country'].unique())\n",
    "    \n",
    "    country_mapping = {\n",
    "        'Brazil': 'br',\n",
    "        'United States': 'us',\n",
    "        'Greece': 'gr',\n",
    "        'United Kingdom': 'uk',\n",
    "        'China': 'cn',\n",
    "        'Italy': 'it',\n",
    "        'India': 'in',\n",
    "        'Spain': 'es',\n",
    "        'Germany': 'de',\n",
    "        'France': 'fr',\n",
    "        'Turkey': 'tr',\n",
    "        'South Korea': 'kr',\n",
    "        'Japan': 'jp',\n",
    "        'Russia': 'ru',\n",
    "        'Canada': 'ca',\n",
    "        'Australia': 'au',\n",
    "        'Mexico': 'mx',\n",
    "        'Netherlands': 'nl',\n",
    "        'Argentina': 'ar',\n",
    "        'Sweden': 'se',\n",
    "        'Norway': 'no',\n",
    "        'Finland': 'fi',\n",
    "        'Denmark': 'dk',\n",
    "        'Belgium': 'be',\n",
    "        'Poland': 'pl',\n",
    "        'Portugal': 'pt',\n",
    "        'Switzerland': 'ch',\n",
    "        'Austria': 'at',\n",
    "        # Adicione outros países conforme necessário\n",
    "    }\n",
    "    df['country'] = df['country'].apply(lambda x: country_mapping[x] if x in country_mapping else 'other')\n",
    "    \n",
    "    df['time_per_week'] = pd.cut(df['time_per_week'], bins=[0, 5, 15, 25, 30, float('inf')], \n",
    "                                labels=['<5', '5-15', '16-25', '26-30', '>30'])\n",
    "    df['game_genre'] = df['game_genre'].str.split(':').str[0].str.lower()\n",
    "    \n",
    "    df['game_setting'] = df['game_setting'].str.contains('Multiplayer', case=False)\n",
    "    df = df.rename(columns={\"game_setting\": \"setting_multiplayer\"})\n",
    "    \n",
    "    print(\"Primeiras linhas do dataset:\")\n",
    "    print(df.head())  # Exibe as primeiras linhas do DataFrame\n",
    "    \n",
    "    # Salvar o DataFrame limpo (opcional)\n",
    "    cleaned_file_path = \"assets/Cleaned_\" + csv_filename\n",
    "    df.to_csv(cleaned_file_path, index=False)\n",
    "    print(f\"\\nDataset limpo salvo em: {cleaned_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o arquivo CSV: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c414cd",
   "metadata": {},
   "source": [
    "## Filtro de Canônicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8ba5f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame filtrado:\n",
      "   gender age_group country years_playing time_per_week game_genre  \\\n",
      "0    male     25-34      uk         21-30         26-30     action   \n",
      "1    male       <15      us           <10         26-30     action   \n",
      "2  female     15-24      us           <10            <5     action   \n",
      "3    male     15-24      br         10-20          5-15     action   \n",
      "4    male     15-24      br         10-20            <5     action   \n",
      "\n",
      "   setting_multiplayer  points  levels  cooperation  ...  acknowledgment  \\\n",
      "0                False       4       5            3  ...               5   \n",
      "1                False       2       2            3  ...               1   \n",
      "2                 True       5       4            4  ...               4   \n",
      "3                False       5       4            2  ...               3   \n",
      "4                False       2       3            4  ...               5   \n",
      "\n",
      "   stats  rarity  imposed_choice  time_pressure  economy  sensation  \\\n",
      "0      4       4               3              2        4          4   \n",
      "1      5       4               2              2        2          5   \n",
      "2      3       3               4              2        4          3   \n",
      "3      5       2               3              1        5          5   \n",
      "4      3       2               3              3        2          4   \n",
      "\n",
      "   reputation  narrative  storytelling  \n",
      "0           4          5             5  \n",
      "1           1          4             4  \n",
      "2           3          5             4  \n",
      "3           1          5             5  \n",
      "4           3          2             2  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df.copy()\n",
    "\n",
    "for column, values in filterBy.items():\n",
    "        if column in df.columns:\n",
    "            filtered_df = filtered_df[df[column].isin(values)]\n",
    "            \n",
    "# Exibir o DataFrame filtrado\n",
    "print(\"\\nDataFrame filtrado:\")\n",
    "print(filtered_df.head())  # Exibe as primeiras linhas do DataFrame filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80881e8b",
   "metadata": {},
   "source": [
    "## Binarização de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a200b3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removendo 7 colunas de binarização que estão presentes em filterBy.\n",
      "DataFrame binarizado:\n",
      "   gender_female  gender_male  gender_other  age_group_<15  age_group_15-24  \\\n",
      "0          False         True         False          False            False   \n",
      "1          False         True         False           True            False   \n",
      "2           True        False         False          False             True   \n",
      "3          False         True         False          False             True   \n",
      "4          False         True         False          False             True   \n",
      "\n",
      "   age_group_25-34  age_group_35-44  age_group_>44  country_at  country_au  \\\n",
      "0             True            False          False       False       False   \n",
      "1            False            False          False       False       False   \n",
      "2            False            False          False       False       False   \n",
      "3            False            False          False       False       False   \n",
      "4            False            False          False       False       False   \n",
      "\n",
      "   ...  sensation_high  reputation_low  reputation_medium  reputation_high  \\\n",
      "0  ...               1               0                  0                1   \n",
      "1  ...               1               1                  0                0   \n",
      "2  ...               0               0                  1                0   \n",
      "3  ...               1               1                  0                0   \n",
      "4  ...               1               0                  1                0   \n",
      "\n",
      "   narrative_low  narrative_medium  narrative_high  storytelling_low  \\\n",
      "0              0                 0               1                 0   \n",
      "1              0                 0               1                 0   \n",
      "2              0                 0               1                 0   \n",
      "3              0                 0               1                 0   \n",
      "4              1                 0               0                 1   \n",
      "\n",
      "   storytelling_medium  storytelling_high  \n",
      "0                    0                  1  \n",
      "1                    0                  1  \n",
      "2                    0                  1  \n",
      "3                    0                  1  \n",
      "4                    0                  0  \n",
      "\n",
      "[5 rows x 122 columns]\n",
      "\n",
      "Dataset binarizado salvo em: assets/Binarized_SAGEDataset.csv\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "columns_to_binarize = ['gender', 'age_group', 'country', 'years_playing', 'time_per_week', 'game_genre', 'setting_multiplayer']\n",
    "df_binarized = pd.get_dummies(df, columns=columns_to_binarize, prefix=columns_to_binarize)\n",
    "# Remover itens de columns_to_binarize que estão presentes como chaves em filterBy\n",
    "columns_to_binarize = [col for col in columns_to_binarize if col not in filterBy.keys()]\n",
    "# Print se algum item foi removido\n",
    "if len(columns_to_binarize) != len(df.columns):\n",
    "    print(f\"Removendo {len(columns_to_binarize)} colunas de binarização que estão presentes em filterBy.\")\n",
    "\n",
    "# Exemplo: Transformar a coluna 'points' em colunas binárias 'points_low', 'points_medium', 'points_high'\n",
    "def transform_scale_to_binary(df, column_name):\n",
    "    df[f'{column_name}_low'] = df[column_name].apply(lambda x: 1 if x in [1, 2] else 0)\n",
    "    df[f'{column_name}_medium'] = df[column_name].apply(lambda x: 1 if x == 3 else 0)\n",
    "    df[f'{column_name}_high'] = df[column_name].apply(lambda x: 1 if x in [4, 5] else 0)\n",
    "    df.drop(column_name, axis=1, inplace=True)\n",
    "    \n",
    "# Aplicar a transformação para as colunas desejadas\n",
    "columns_to_transform = ['points', 'levels', 'cooperation', 'competition', 'renovation',\n",
    "                        'progression', 'objectives', 'puzzles', 'novelty', 'chances',\n",
    "                         'social_pressure', 'acknowledgment', 'stats', 'rarity',\n",
    "                         'imposed_choice', 'time_pressure', 'economy', 'sensation',\n",
    "                         'reputation', 'narrative', 'storytelling']  # Substitua pelos nomes das colunas que deseja transformar\n",
    "for col in columns_to_transform:\n",
    "    if col in df_binarized.columns:\n",
    "        transform_scale_to_binary(df_binarized, col)\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame binarizado\n",
    "print(\"DataFrame binarizado:\")\n",
    "print(df_binarized.head())\n",
    "\n",
    "# Salvar o DataFrame binarizado (opcional)\n",
    "binarized_file_path = \"assets/Binarized_\" + csv_filename\n",
    "df_binarized.to_csv(binarized_file_path, index=False)\n",
    "print(f\"\\nDataset binarizado salvo em: {binarized_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c7cf2f",
   "metadata": {},
   "source": [
    "## Execução do Algoritmo Apriori\n",
    "\n",
    "Nesse processo serão definidos algumas variáveis iniciais e depois a mineração será executada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fde7fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/realima/Work/UFPA/PythonProjects/SAGEMining/.venv/lib/python3.12/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning:\n",
      "\n",
      "DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjuntos frequentes:\n",
      "      support                                           itemsets\n",
      "0    0.320042                                    (gender_female)\n",
      "1    0.672613                                      (gender_male)\n",
      "2    0.375656                                  (age_group_15-24)\n",
      "3    0.398216                                  (age_group_25-34)\n",
      "4    0.458027                                       (country_us)\n",
      "..        ...                                                ...\n",
      "815  0.315845  (narrative_high, setting_multiplayer_False, pr...\n",
      "816  0.306925  (stats_high, narrative_high, progression_high,...\n",
      "817  0.317943  (narrative_high, progression_high, objectives_...\n",
      "818  0.327912  (narrative_high, progression_high, objectives_...\n",
      "819  0.317943  (stats_high, narrative_high, progression_high,...\n",
      "\n",
      "[820 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "frequent_itemsets = apriori(df_binarized, min_support=min_support, use_colnames=True)\n",
    "\n",
    "print(\"\\nConjuntos frequentes:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Gerar regras de associação\n",
    "num_itemsets = df.columns.size # Número total de colunas no começo do tratamento\n",
    "rules = association_rules(frequent_itemsets, num_itemsets=num_itemsets, metric=\"confidence\", min_threshold=confidence)\n",
    "\n",
    "#Aplicando filtro no antecedents e consequents dos resultados\n",
    "rules = rules[rules['antecedents'].apply(len) + rules['consequents'].apply(len) > min_products]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2522729a",
   "metadata": {},
   "source": [
    "# Plotting de Resultados\n",
    "Pesquisando maneiras de visualizar os resultados de associação encontrei um artigo que apresentava de maneira intuitiva e interativa o plot do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25843330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regras de associação:\n",
      "                                           antecedents  \\\n",
      "283  progression_high, setting_multiplayer_False, g...   \n",
      "284  objectives_high, setting_multiplayer_False, ge...   \n",
      "285  sensation_high, setting_multiplayer_False, gen...   \n",
      "286  narrative_high, setting_multiplayer_False, gen...   \n",
      "287  storytelling_high, setting_multiplayer_False, ...   \n",
      "..                                                 ...   \n",
      "867  stats_high, narrative_high, objectives_high, s...   \n",
      "868  stats_high, progression_high, objectives_high,...   \n",
      "869  objectives_high, stats_high, narrative_high, s...   \n",
      "870  sensation_high, stats_high, narrative_high, st...   \n",
      "871  sensation_high, stats_high, objectives_high, s...   \n",
      "\n",
      "                             consequents  antecedent support  \\\n",
      "283                      objectives_high            0.401364   \n",
      "284                     progression_high            0.375656   \n",
      "285                     progression_high            0.343652   \n",
      "286                     progression_high            0.366212   \n",
      "287                     progression_high            0.372508   \n",
      "..                                   ...                 ...   \n",
      "867                     progression_high            0.333158   \n",
      "868                       narrative_high            0.351522   \n",
      "869  progression_high, storytelling_high            0.360965   \n",
      "870    progression_high, objectives_high            0.370409   \n",
      "871     progression_high, narrative_high            0.373033   \n",
      "\n",
      "     consequent support   support  confidence      lift  representativity  \\\n",
      "283            0.817419  0.344701    0.858824  1.050653               1.0   \n",
      "284            0.858342  0.344701    0.917598  1.069035               1.0   \n",
      "285            0.858342  0.305352    0.888550  1.035193               1.0   \n",
      "286            0.858342  0.333158    0.909742  1.059883               1.0   \n",
      "287            0.858342  0.333683    0.895775  1.043610               1.0   \n",
      "..                  ...       ...         ...       ...               ...   \n",
      "867            0.858342  0.317943    0.954331  1.111830               1.0   \n",
      "868            0.746065  0.317943    0.904478  1.212331               1.0   \n",
      "869            0.683106  0.317943    0.880814  1.289425               1.0   \n",
      "870            0.739244  0.317943    0.858357  1.161127               1.0   \n",
      "871            0.671563  0.317943    0.852321  1.269159               1.0   \n",
      "\n",
      "     leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
      "283  0.016618    1.293284       0.080535  0.394358   0.226775    0.640259  \n",
      "284  0.022260    1.719103       0.103432  0.387611   0.418301    0.659594  \n",
      "285  0.010381    1.271040       0.051796  0.340550   0.213243    0.622148  \n",
      "286  0.018823    1.569480       0.089146  0.373749   0.362846    0.648942  \n",
      "287  0.013944    1.359150       0.066595  0.371930   0.264246    0.642264  \n",
      "..        ...         ...            ...       ...        ...         ...  \n",
      "867  0.031979    3.101820       0.150834  0.363964   0.677609    0.662373  \n",
      "868  0.055685    2.658381       0.270082  0.407806   0.623831    0.665319  \n",
      "869  0.071366    2.658818       0.351249  0.437861   0.623893    0.673126  \n",
      "870  0.044120    1.840934       0.220410  0.401590   0.456797    0.644225  \n",
      "871  0.067428    2.223984       0.338258  0.437545   0.550357    0.662879  \n",
      "\n",
      "[589 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import webbrowser\n",
    "\n",
    "# Converter 'antecedents' e 'consequents' de frozenset para string\n",
    "rules['antecedents'] = rules['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
    "rules['consequents'] = rules['consequents'].apply(lambda x: ', '.join(list(x)))\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    rules,\n",
    "    x='confidence',  # Eixo X\n",
    "    y='lift',        # Eixo Y\n",
    "    z='certainty',   # Eixo Z\n",
    "    color='lift',    # Cor baseada no lift\n",
    "    size='support',  # Tamanho dos pontos baseado no suporte\n",
    "    hover_data=['antecedents', 'consequents'],  # Mostrar os antecedentes e consequentes ao passar o mouse\n",
    "    title=\"Regras de Associação: Confidence, Lift e Certainty\"\n",
    ")\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig.write_html('plot.html')\n",
    "# Caminho para o arquivo HTML gerado\n",
    "plot_file_path = os.path.abspath(\"plot.html\")\n",
    "\n",
    "# Abrir o arquivo no navegador padrão\n",
    "webbrowser.open(f\"file://{plot_file_path}\")\n",
    "# Exibir as regras de associação\n",
    "print(\"\\nRegras de associação:\")\n",
    "rule_file_path = \"assets/rules_\" + csv_filename\n",
    "rules.to_csv(rule_file_path, index=False)\n",
    "print(rules) #Também é possível acessar depois da execução o wrangler das regras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
